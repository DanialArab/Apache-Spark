{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f56c69c",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "https://spark.apache.org/docs/latest/ml-classification-regression.html#logistic-regression\n",
    "\n",
    "\n",
    "Evaluators will be a very important part of our pipline when working with Machine Learning:\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.evaluation.BinaryClassificationEvaluator.html#pyspark.ml.evaluation.BinaryClassificationEvaluator.metricName\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.evaluation.MulticlassClassificationEvaluator.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1525e1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/danial/Desktop/myspark/Apache-Spark/Python-and-Spark-for-Big-Data-master/Spark_for_Machine_Learning/Logistic_Regression/sample_libsvm_data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f9d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78662313",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init(\"/home/danial/spark-3.3.2-bin-hadoop3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0141841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79f6c476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/04 11:17:00 WARN Utils: Your hostname, danial-VirtualBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "23/04/04 11:17:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/04 11:17:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/04/04 11:17:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('logis').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "670dff66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/04 11:19:29 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = spark.read.format('libsvm').load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "081784d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "|  1.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[151,152,153...|\n",
      "|  0.0|(692,[129,130,131...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[99,100,101,...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[153,154,155...|\n",
      "|  0.0|(692,[151,152,153...|\n",
      "|  1.0|(692,[129,130,131...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  1.0|(692,[150,151,152...|\n",
      "|  0.0|(692,[124,125,126...|\n",
      "|  0.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[97,98,99,12...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6a699a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|label|\n",
      "+-----+\n",
      "|  0.0|\n",
      "|  1.0|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('label').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a492c77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68cd7d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55fa57a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "54c940e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_model = lg.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b18453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_summary = lg_model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "61746552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_summary.predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6c1af61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(692,[98,99,100,1...|[25.1513018780422...|[0.99999999998806...|       0.0|\n",
      "|  0.0|(692,[121,122,123...|[26.0753841057895...|[0.99999999999526...|       0.0|\n",
      "|  0.0|(692,[122,123,124...|[20.2151747204161...|[0.99999999833788...|       0.0|\n",
      "|  0.0|(692,[122,123,148...|[22.3056083865609...|[0.99999999979450...|       0.0|\n",
      "|  0.0|(692,[123,124,125...|[24.0462456874123...|[0.99999999996395...|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[33.1079069148920...|[0.99999999999999...|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[34.1141437492309...|[0.99999999999999...|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[36.4386030338422...|[0.99999999999999...|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[22.1688960637801...|[0.99999999976440...|       0.0|\n",
      "|  0.0|(692,[125,126,127...|[29.6063108984909...|[0.99999999999986...|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[32.2947820780320...|[0.99999999999999...|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[20.5614228952192...|[0.99999999882432...|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[22.1463660729811...|[0.99999999975903...|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[26.0020921630802...|[0.99999999999490...|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[20.9660471008558...|[0.99999999921555...|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[26.3809835658767...|[0.99999999999650...|       0.0|\n",
      "|  0.0|(692,[150,151,152...|[21.1975025107053...|[0.99999999937764...|       0.0|\n",
      "|  0.0|(692,[151,152,153...|[33.9776034347491...|[0.99999999999999...|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[21.3279892869869...|[0.99999999945377...|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[33.5378538511090...|[0.99999999999999...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_summary.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "60c90bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "203e3857",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_and_labels = lg_model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4496ae0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(692,[98,99,100,1...|[25.1513018780422...|[0.99999999998806...|       0.0|\n",
      "|  0.0|(692,[100,101,102...|[2.22487928435347...|[0.90246153751556...|       0.0|\n",
      "|  0.0|(692,[121,122,123...|[26.0753841057895...|[0.99999999999526...|       0.0|\n",
      "|  0.0|(692,[123,124,125...|[36.1540641835322...|[0.99999999999999...|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[21.0332131007928...|[0.99999999926651...|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[21.9067180479556...|[0.99999999969378...|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[16.3898344184417...|[0.99999992379467...|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[20.9660471008558...|[0.99999999921555...|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[26.3809835658767...|[0.99999999999650...|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[22.6986054178073...|[0.99999999986128...|       0.0|\n",
      "|  0.0|(692,[150,151,152...|[21.1975025107053...|[0.99999999937764...|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[33.5378538511090...|[0.99999999999999...|       0.0|\n",
      "|  1.0|(692,[99,100,101,...|[-19.450612468096...|[3.57031335082489...|       1.0|\n",
      "|  1.0|(692,[124,125,126...|[-20.002424273394...|[2.05616287023511...|       1.0|\n",
      "|  1.0|(692,[124,125,126...|[-20.342715320638...|[1.46308982043348...|       1.0|\n",
      "|  1.0|(692,[125,126,127...|[-19.996514824599...|[2.06834963246365...|       1.0|\n",
      "|  1.0|(692,[125,126,127...|[-19.471578666404...|[3.49623671956100...|       1.0|\n",
      "|  1.0|(692,[125,126,153...|[-20.498473939733...|[1.25206212989156...|       1.0|\n",
      "|  1.0|(692,[126,127,128...|[-21.789174833466...|[3.44414640604879...|       1.0|\n",
      "|  1.0|(692,[126,127,128...|[-21.076932169994...|[7.02109198418946...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_and_labels.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6b2ce989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import (BinaryClassificationEvaluator,\n",
    "                                    MulticlassClassificationEvaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73b6d40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_eval = BinaryClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "94cd0a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# areaUnderROC:\n",
    "\n",
    "my_final_roc = my_eval.evaluate(predictions_and_labels.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c3e6704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_final_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e80783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/danial/Desktop/myspark/Apache-Spark/Python-and-Spark-for-Big-Data-master/Spark_for_Machine_Learning/Logistic_Regression/titanic.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39cfc639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/danial/spark-3.3.2-bin-hadoop3')\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "640d46b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/06 08:30:17 WARN Utils: Your hostname, danial-VirtualBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "23/04/06 08:30:17 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/06 08:30:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('titanic').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1c333fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44797b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07b1e324",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bd5c8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Survived',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7544787",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_columns = df.select(['Survived',\n",
    "                     'Pclass',\n",
    "                     'Sex',\n",
    "                     'Age',\n",
    "                     'SibSp',\n",
    "                     'Parch',\n",
    "                     'Fare',\n",
    "                     'Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bbf476f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+-------+--------+\n",
      "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|\n",
      "+--------+------+------+----+-----+-----+-------+--------+\n",
      "|       0|     3|  male|22.0|    1|    0|   7.25|       S|\n",
      "|       1|     1|female|38.0|    1|    0|71.2833|       C|\n",
      "|       1|     3|female|26.0|    0|    0|  7.925|       S|\n",
      "|       1|     1|female|35.0|    1|    0|   53.1|       S|\n",
      "|       0|     3|  male|35.0|    0|    0|   8.05|       S|\n",
      "|       0|     3|  male|null|    0|    0| 8.4583|       Q|\n",
      "|       0|     1|  male|54.0|    0|    0|51.8625|       S|\n",
      "|       0|     3|  male| 2.0|    3|    1| 21.075|       S|\n",
      "|       1|     3|female|27.0|    0|    2|11.1333|       S|\n",
      "|       1|     2|female|14.0|    1|    0|30.0708|       C|\n",
      "|       1|     3|female| 4.0|    1|    1|   16.7|       S|\n",
      "|       1|     1|female|58.0|    0|    0|  26.55|       S|\n",
      "|       0|     3|  male|20.0|    0|    0|   8.05|       S|\n",
      "|       0|     3|  male|39.0|    1|    5| 31.275|       S|\n",
      "|       0|     3|female|14.0|    0|    0| 7.8542|       S|\n",
      "|       1|     2|female|55.0|    0|    0|   16.0|       S|\n",
      "|       0|     3|  male| 2.0|    4|    1| 29.125|       Q|\n",
      "|       1|     2|  male|null|    0|    0|   13.0|       S|\n",
      "|       0|     3|female|31.0|    1|    0|   18.0|       S|\n",
      "|       1|     3|female|null|    0|    0|  7.225|       C|\n",
      "+--------+------+------+----+-----+-----+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_columns.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2477ea46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_columns.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6b23fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_columns.isN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14c3c12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+---+-----+-----+----+--------+\n",
      "|Survived|Pclass|Sex|Age|SibSp|Parch|Fare|Embarked|\n",
      "+--------+------+---+---+-----+-----+----+--------+\n",
      "|       0|     0|  0|177|    0|    0|   0|       2|\n",
      "+--------+------+---+---+-----+-----+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "missing_counts = my_columns.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in my_columns.columns])\n",
    "\n",
    "# Print the missing value counts for each column\n",
    "missing_counts.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65da9419",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_final_data = my_columns.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f41c038f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+---+-----+-----+----+--------+\n",
      "|Survived|Pclass|Sex|Age|SibSp|Parch|Fare|Embarked|\n",
      "+--------+------+---+---+-----+-----+----+--------+\n",
      "|       0|     0|  0|  0|    0|    0|   0|       0|\n",
      "+--------+------+---+---+-----+-----+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_final_data.select([sum(col(c).isNull().cast('int')).alias(c) for c in my_final_data.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28d42673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "712"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_final_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c63cb829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_final_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9203e37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+-------+--------+\n",
      "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|\n",
      "+--------+------+------+----+-----+-----+-------+--------+\n",
      "|       0|     3|  male|22.0|    1|    0|   7.25|       S|\n",
      "|       1|     1|female|38.0|    1|    0|71.2833|       C|\n",
      "|       1|     3|female|26.0|    0|    0|  7.925|       S|\n",
      "|       1|     1|female|35.0|    1|    0|   53.1|       S|\n",
      "|       0|     3|  male|35.0|    0|    0|   8.05|       S|\n",
      "|       0|     1|  male|54.0|    0|    0|51.8625|       S|\n",
      "|       0|     3|  male| 2.0|    3|    1| 21.075|       S|\n",
      "|       1|     3|female|27.0|    0|    2|11.1333|       S|\n",
      "|       1|     2|female|14.0|    1|    0|30.0708|       C|\n",
      "|       1|     3|female| 4.0|    1|    1|   16.7|       S|\n",
      "|       1|     1|female|58.0|    0|    0|  26.55|       S|\n",
      "|       0|     3|  male|20.0|    0|    0|   8.05|       S|\n",
      "|       0|     3|  male|39.0|    1|    5| 31.275|       S|\n",
      "|       0|     3|female|14.0|    0|    0| 7.8542|       S|\n",
      "|       1|     2|female|55.0|    0|    0|   16.0|       S|\n",
      "|       0|     3|  male| 2.0|    4|    1| 29.125|       Q|\n",
      "|       0|     3|female|31.0|    1|    0|   18.0|       S|\n",
      "|       0|     2|  male|35.0|    0|    0|   26.0|       S|\n",
      "|       1|     2|  male|34.0|    0|    0|   13.0|       S|\n",
      "|       1|     3|female|15.0|    0|    0| 8.0292|       Q|\n",
      "+--------+------+------+----+-----+-----+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7dd71c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8f095674",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_indexer = StringIndexer(inputCol='Sex', outputCol='SexIndex')\n",
    "gender_encoder = OneHotEncoder(inputCol='SexIndex', outputCol='SexVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d882239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embark_indexer = StringIndexer(inputCol='Embarked', outputCol='EmbarkedIndex')\n",
    "embark_encoder = OneHotEncoder(inputCol='EmbarkedIndex', outputCol='EmbarkedVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7046f0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['Pclass', 'SexVec', 'Age', 'SibSp',\n",
    "                                       'Parch', 'Fare', 'EmbarkedVec'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9865cad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_titanic = LogisticRegression(featuresCol='features', labelCol='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e26056d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages =[gender_indexer, embark_indexer,\n",
    "                             gender_encoder, embark_encoder,\n",
    "                             assembler, log_reg_titanic\n",
    "                                                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "155304cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = my_final_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d53fb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 36:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/06 09:10:15 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/04/06 09:10:15 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n"
     ]
    }
   ],
   "source": [
    "fit_model = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b0c0e215",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = fit_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9c226367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0ec57c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "20464865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|Survived|prediction|\n",
      "+--------+----------+\n",
      "|       0|       1.0|\n",
      "|       0|       1.0|\n",
      "|       0|       1.0|\n",
      "|       0|       1.0|\n",
      "|       0|       0.0|\n",
      "|       0|       1.0|\n",
      "|       0|       1.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       1.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.select('Survived', 'prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1df12b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.750515767757147"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC =  my_eval.evaluate(results)\n",
    "AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2eb059",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6db96f6",
   "metadata": {},
   "source": [
    "# Spark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d48f2c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/danial/spark-3.3.2-bin-hadoop3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccb21020",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6194b292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/31 09:21:52 WARN Utils: Your hostname, danial-VirtualBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "23/03/31 09:21:52 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/31 09:21:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Basics').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4d3ce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'Python-and-Spark-for-Big-Data-master/Spark_DataFrames/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc1ff515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "path = 'Python-and-Spark-for-Big-Data-master/Spark_DataFrames/people.json' \n",
    "\n",
    "df = spark.read.json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "785b60c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9c85fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c523542b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'name']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2d9f581",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, age: string, name: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e632cf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------+\n",
      "|summary|               age|   name|\n",
      "+-------+------------------+-------+\n",
      "|  count|                 2|      3|\n",
      "|   mean|              24.5|   null|\n",
      "| stddev|7.7781745930520225|   null|\n",
      "|    min|                19|   Andy|\n",
      "|    max|                30|Michael|\n",
      "+-------+------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0d1ca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (StructType, StructField,\n",
    "                               IntegerType, StringType)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63aa2f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schema = [StructField('age', IntegerType(), True),\n",
    "               StructField('name', StringType(), True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e56b405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_struc = StructType(fields=data_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ca37bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(path, schema=final_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2f4e260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e62e327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb6b6497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'age'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0da0b3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.column.Column"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71e7baa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f03bf636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.select('age'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8abd1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| age|\n",
      "+----+\n",
      "|null|\n",
      "|  30|\n",
      "|  19|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "694d1417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=None, name='Michael'), Row(age=30, name='Andy')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f129d33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(age=None, name='Michael')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1e97815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "140a5c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.types.Row"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.head(2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e5b3311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, name: string]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(['age', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a599049f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['age', 'name']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a3ff5011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, name: string, new_age: int]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.withColumn('new_age', df['age']*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b4df87ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5fe9fdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-------+\n",
      "| age|   name|new_age|\n",
      "+----+-------+-------+\n",
      "|null|Michael|   null|\n",
      "|  30|   Andy|     60|\n",
      "|  19| Justin|     38|\n",
      "+----+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('new_age', df['age']*2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e404631",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'DataFrame' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_age\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m)\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'DataFrame' and 'int'"
     ]
    }
   ],
   "source": [
    "df.withColumn('new_age', df.select('age')*2).show() # so i do need to have a column object here not a dataframe like above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1f3fe35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6895bc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0ad4de8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|my_age|   name|\n",
      "+------+-------+\n",
      "|  null|Michael|\n",
      "|    30|   Andy|\n",
      "|    19| Justin|\n",
      "+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed('age', 'my_age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a29e8f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "baf1ef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('people')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2b55b1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = spark.sql(\"SELECT * FROM people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a4fe257a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eca7fb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results = spark.sql(\"SELECT * FROM people WHERE age=30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8cc03b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "|age|name|\n",
      "+---+----+\n",
      "| 30|Andy|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d108848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba71f48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/31 13:40:29 WARN Utils: Your hostname, danial-VirtualBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "23/03/31 13:40:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/31 13:40:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/03/31 13:40:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('ops').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62fe077d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python-and-Spark-for-Big-Data-master/Spark_DataFrames/'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b630eee9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(directory + 'appl_stock.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d105e967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba006765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|               Date|              Open|              High|               Low|             Close|   Volume|         Adj Close|\n",
      "+-------------------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|2010-01-04 00:00:00|        213.429998|        214.499996|212.38000099999996|        214.009998|123432400|         27.727039|\n",
      "|2010-01-05 00:00:00|        214.599998|        215.589994|        213.249994|        214.379993|150476200|27.774976000000002|\n",
      "|2010-01-06 00:00:00|        214.379993|            215.23|        210.750004|        210.969995|138040000|27.333178000000004|\n",
      "|2010-01-07 00:00:00|            211.75|        212.000006|        209.050005|            210.58|119282800|          27.28265|\n",
      "|2010-01-08 00:00:00|        210.299994|        212.000006|209.06000500000002|211.98000499999998|111902700|         27.464034|\n",
      "|2010-01-11 00:00:00|212.79999700000002|        213.000002|        208.450005|210.11000299999998|115557400|         27.221758|\n",
      "|2010-01-12 00:00:00|209.18999499999998|209.76999500000002|        206.419998|        207.720001|148614900|          26.91211|\n",
      "|2010-01-13 00:00:00|        207.870005|210.92999500000002|        204.099998|        210.650002|151473000|          27.29172|\n",
      "|2010-01-14 00:00:00|210.11000299999998|210.45999700000002|        209.020004|            209.43|108223500|         27.133657|\n",
      "|2010-01-15 00:00:00|210.92999500000002|211.59999700000003|        205.869999|            205.93|148516900|26.680197999999997|\n",
      "|2010-01-19 00:00:00|        208.330002|215.18999900000003|        207.240004|        215.039995|182501900|27.860484999999997|\n",
      "|2010-01-20 00:00:00|        214.910006|        215.549994|        209.500002|            211.73|153038200|         27.431644|\n",
      "|2010-01-21 00:00:00|        212.079994|213.30999599999998|        207.210003|        208.069996|152038600|         26.957455|\n",
      "|2010-01-22 00:00:00|206.78000600000001|        207.499996|            197.16|            197.75|220441900|         25.620401|\n",
      "|2010-01-25 00:00:00|202.51000200000001|        204.699999|        200.190002|        203.070002|266424900|26.309658000000002|\n",
      "|2010-01-26 00:00:00|205.95000100000001|        213.710005|        202.580004|        205.940001|466777500|         26.681494|\n",
      "|2010-01-27 00:00:00|        206.849995|            210.58|        199.530001|        207.880005|430642100|26.932840000000002|\n",
      "|2010-01-28 00:00:00|        204.930004|        205.500004|        198.699995|        199.289995|293375600|25.819922000000002|\n",
      "|2010-01-29 00:00:00|        201.079996|        202.199995|        190.250002|        192.060003|311488100|         24.883208|\n",
      "|2010-02-01 00:00:00|192.36999699999998|             196.0|191.29999899999999|        194.729998|187469100|         25.229131|\n",
      "+-------------------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b34cc89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Date=datetime.datetime(2010, 1, 4, 0, 0), Open=213.429998, High=214.499996, Low=212.38000099999996, Close=214.009998, Volume=123432400, Adj Close=27.727039),\n",
       " Row(Date=datetime.datetime(2010, 1, 5, 0, 0), Open=214.599998, High=215.589994, Low=213.249994, Close=214.379993, Volume=150476200, Adj Close=27.774976000000002),\n",
       " Row(Date=datetime.datetime(2010, 1, 6, 0, 0), Open=214.379993, High=215.23, Low=210.750004, Close=210.969995, Volume=138040000, Adj Close=27.333178000000004)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91bd5214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Date=datetime.datetime(2010, 1, 4, 0, 0), Open=213.429998, High=214.499996, Low=212.38000099999996, Close=214.009998, Volume=123432400, Adj Close=27.727039)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "742fb3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|               Date|              Open|              High|               Low|             Close|   Volume|         Adj Close|\n",
      "+-------------------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|2010-01-04 00:00:00|        213.429998|        214.499996|212.38000099999996|        214.009998|123432400|         27.727039|\n",
      "|2010-01-05 00:00:00|        214.599998|        215.589994|        213.249994|        214.379993|150476200|27.774976000000002|\n",
      "|2010-01-06 00:00:00|        214.379993|            215.23|        210.750004|        210.969995|138040000|27.333178000000004|\n",
      "|2010-01-07 00:00:00|            211.75|        212.000006|        209.050005|            210.58|119282800|          27.28265|\n",
      "|2010-01-08 00:00:00|        210.299994|        212.000006|209.06000500000002|211.98000499999998|111902700|         27.464034|\n",
      "|2010-01-11 00:00:00|212.79999700000002|        213.000002|        208.450005|210.11000299999998|115557400|         27.221758|\n",
      "|2010-01-12 00:00:00|209.18999499999998|209.76999500000002|        206.419998|        207.720001|148614900|          26.91211|\n",
      "|2010-01-13 00:00:00|        207.870005|210.92999500000002|        204.099998|        210.650002|151473000|          27.29172|\n",
      "|2010-01-14 00:00:00|210.11000299999998|210.45999700000002|        209.020004|            209.43|108223500|         27.133657|\n",
      "|2010-01-15 00:00:00|210.92999500000002|211.59999700000003|        205.869999|            205.93|148516900|26.680197999999997|\n",
      "|2010-01-19 00:00:00|        208.330002|215.18999900000003|        207.240004|        215.039995|182501900|27.860484999999997|\n",
      "|2010-01-20 00:00:00|        214.910006|        215.549994|        209.500002|            211.73|153038200|         27.431644|\n",
      "|2010-01-21 00:00:00|        212.079994|213.30999599999998|        207.210003|        208.069996|152038600|         26.957455|\n",
      "|2010-01-22 00:00:00|206.78000600000001|        207.499996|            197.16|            197.75|220441900|         25.620401|\n",
      "|2010-01-25 00:00:00|202.51000200000001|        204.699999|        200.190002|        203.070002|266424900|26.309658000000002|\n",
      "|2010-01-26 00:00:00|205.95000100000001|        213.710005|        202.580004|        205.940001|466777500|         26.681494|\n",
      "|2010-01-27 00:00:00|        206.849995|            210.58|        199.530001|        207.880005|430642100|26.932840000000002|\n",
      "|2010-01-28 00:00:00|        204.930004|        205.500004|        198.699995|        199.289995|293375600|25.819922000000002|\n",
      "|2010-01-29 00:00:00|        201.079996|        202.199995|        190.250002|        192.060003|311488100|         24.883208|\n",
      "|2010-02-01 00:00:00|192.36999699999998|             196.0|191.29999899999999|        194.729998|187469100|         25.229131|\n",
      "+-------------------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"Close < 500\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c24ae768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|              Open|             Close|\n",
      "+------------------+------------------+\n",
      "|        213.429998|        214.009998|\n",
      "|        214.599998|        214.379993|\n",
      "|        214.379993|        210.969995|\n",
      "|            211.75|            210.58|\n",
      "|        210.299994|211.98000499999998|\n",
      "|212.79999700000002|210.11000299999998|\n",
      "|209.18999499999998|        207.720001|\n",
      "|        207.870005|        210.650002|\n",
      "|210.11000299999998|            209.43|\n",
      "|210.92999500000002|            205.93|\n",
      "|        208.330002|        215.039995|\n",
      "|        214.910006|            211.73|\n",
      "|        212.079994|        208.069996|\n",
      "|206.78000600000001|            197.75|\n",
      "|202.51000200000001|        203.070002|\n",
      "|205.95000100000001|        205.940001|\n",
      "|        206.849995|        207.880005|\n",
      "|        204.930004|        199.289995|\n",
      "|        201.079996|        192.060003|\n",
      "|192.36999699999998|        194.729998|\n",
      "+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"Close < 500\").select([\"Open\", \"Close\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "855b18ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|              Open|             Close|\n",
      "+------------------+------------------+\n",
      "|        213.429998|        214.009998|\n",
      "|        214.599998|        214.379993|\n",
      "|        214.379993|        210.969995|\n",
      "|            211.75|            210.58|\n",
      "|        210.299994|211.98000499999998|\n",
      "|212.79999700000002|210.11000299999998|\n",
      "|209.18999499999998|        207.720001|\n",
      "|        207.870005|        210.650002|\n",
      "|210.11000299999998|            209.43|\n",
      "|210.92999500000002|            205.93|\n",
      "|        208.330002|        215.039995|\n",
      "|        214.910006|            211.73|\n",
      "|        212.079994|        208.069996|\n",
      "|206.78000600000001|            197.75|\n",
      "|202.51000200000001|        203.070002|\n",
      "|205.95000100000001|        205.940001|\n",
      "|        206.849995|        207.880005|\n",
      "|        204.930004|        199.289995|\n",
      "|        201.079996|        192.060003|\n",
      "|192.36999699999998|        194.729998|\n",
      "+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df[\"Close\"] < 500).select([\"Open\", \"Close\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81888df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|               Date|              Open|              High|               Low|             Close|   Volume|         Adj Close|\n",
      "+-------------------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|2010-02-01 00:00:00|192.36999699999998|             196.0|191.29999899999999|        194.729998|187469100|         25.229131|\n",
      "|2010-02-02 00:00:00|        195.909998|        196.319994|193.37999299999998|        195.859997|174585600|25.375532999999997|\n",
      "|2010-02-03 00:00:00|        195.169994|        200.200003|        194.420004|        199.229994|153832000|25.812148999999998|\n",
      "|2010-02-04 00:00:00|        196.730003|        198.370001|        191.570005|        192.050003|189413000|         24.881912|\n",
      "|2010-02-05 00:00:00|192.63000300000002|             196.0|        190.850002|        195.460001|212576700|25.323710000000002|\n",
      "|2010-02-08 00:00:00|        195.690006|197.88000300000002|        193.999994|194.11999699999998|119567700|           25.1501|\n",
      "|2010-02-09 00:00:00|        196.419996|        197.499994|        194.749998|196.19000400000002|158221700|         25.418289|\n",
      "|2010-02-10 00:00:00|        195.889997|             196.6|            194.26|195.12000700000002| 92590400|          25.27966|\n",
      "|2010-02-11 00:00:00|        194.880001|        199.750006|194.05999599999998|        198.669994|137586400|         25.739595|\n",
      "|2010-02-12 00:00:00|        198.109995|        201.639996|        195.500002|200.37999299999998|163867200|25.961142000000002|\n",
      "|2010-02-23 00:00:00|        199.999998|        201.330002|        195.709993|        197.059998|143773700|         25.531005|\n",
      "|2010-02-24 00:00:00|        198.229998|201.44000400000002|        197.840002|            200.66|115141600|         25.997419|\n",
      "|2010-02-25 00:00:00|        197.380005|        202.859997|        196.889994|        202.000004|166281500|          26.17103|\n",
      "|2014-06-09 00:00:00|         92.699997|         93.879997|             91.75|         93.699997| 75415000|         88.906324|\n",
      "|2014-06-10 00:00:00|         94.730003|         95.050003|             93.57|             94.25| 62777000|         89.428189|\n",
      "|2014-06-11 00:00:00|         94.129997|         94.760002|         93.470001|         93.860001| 45681000|         89.058142|\n",
      "|2014-06-12 00:00:00|         94.040001|         94.120003|         91.900002|         92.290001| 54749000|         87.568463|\n",
      "|2014-06-13 00:00:00|         92.199997|         92.440002|         90.879997|         91.279999| 54525000|         86.610132|\n",
      "|2014-06-16 00:00:00|         91.510002|             92.75|         91.449997|         92.199997| 35561000|         87.483064|\n",
      "|2014-06-17 00:00:00|         92.309998|         92.699997|         91.800003| 92.08000200000001| 29726000| 87.36920699999999|\n",
      "+-------------------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((df[\"Close\"] < 500) & ~(df[\"Open\"] > 200)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdecf931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+----------+------+------+---------+---------+\n",
      "|               Date|              Open|      High|   Low| Close|   Volume|Adj Close|\n",
      "+-------------------+------------------+----------+------+------+---------+---------+\n",
      "|2010-01-22 00:00:00|206.78000600000001|207.499996|197.16|197.75|220441900|25.620401|\n",
      "+-------------------+------------------+----------+------+------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df[\"Low\"] == 197.16).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bebf51b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df.filter(df[\"Low\"] == 197.16).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30000ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Date=datetime.datetime(2010, 1, 22, 0, 0), Open=206.78000600000001, High=207.499996, Low=197.16, Close=197.75, Volume=220441900, Adj Close=25.620401)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3daa361a",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "291f5912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': datetime.datetime(2010, 1, 22, 0, 0),\n",
       " 'Open': 206.78000600000001,\n",
       " 'High': 207.499996,\n",
       " 'Low': 197.16,\n",
       " 'Close': 197.75,\n",
       " 'Volume': 220441900,\n",
       " 'Adj Close': 25.620401}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.asDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3a19601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220441900"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.asDict()[\"Volume\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95004dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b05b7927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/31 13:45:19 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('aggs').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc4341d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(directory + 'sales_info.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec06483c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|   GOOG|    Sam|200.0|\n",
      "|   GOOG|Charlie|120.0|\n",
      "|   GOOG|  Frank|340.0|\n",
      "|   MSFT|   Tina|600.0|\n",
      "|   MSFT|    Amy|124.0|\n",
      "|   MSFT|Vanessa|243.0|\n",
      "|     FB|   Carl|870.0|\n",
      "|     FB|  Sarah|350.0|\n",
      "|   APPL|   John|250.0|\n",
      "|   APPL|  Linda|130.0|\n",
      "|   APPL|   Mike|750.0|\n",
      "|   APPL|  Chris|350.0|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5901c5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Person: string (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "723ab7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.group.GroupedData at 0x7f67f5bc1db0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy('Company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f99a2597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.group.GroupedData at 0x7f67f5bc0fd0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"Company\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2ed4e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|Company|       avg(Sales)|\n",
      "+-------+-----------------+\n",
      "|   APPL|            370.0|\n",
      "|   GOOG|            220.0|\n",
      "|     FB|            610.0|\n",
      "|   MSFT|322.3333333333333|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby(\"Company\").mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f59ec52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|Company|       avg(Sales)|\n",
      "+-------+-----------------+\n",
      "|   APPL|            370.0|\n",
      "|   GOOG|            220.0|\n",
      "|     FB|            610.0|\n",
      "|   MSFT|322.3333333333333|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Company\").mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a55a1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But Jose used groupBy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7ef34ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Company: string, avg(Sales): double]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(\"Company\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a49bbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|Company|       avg(Sales)|\n",
      "+-------+-----------------+\n",
      "|   APPL|            370.0|\n",
      "|   GOOG|            220.0|\n",
      "|     FB|            610.0|\n",
      "|   MSFT|322.3333333333333|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Company\").mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2f890852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|Company|sum(Sales)|\n",
      "+-------+----------+\n",
      "|   APPL|    1480.0|\n",
      "|   GOOG|     660.0|\n",
      "|     FB|    1220.0|\n",
      "|   MSFT|     967.0|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Company\").sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7ad28a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|Company|max(Sales)|\n",
      "+-------+----------+\n",
      "|   APPL|     750.0|\n",
      "|   GOOG|     340.0|\n",
      "|     FB|     870.0|\n",
      "|   MSFT|     600.0|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Company\").max().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8c1dfc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|Company|count|\n",
      "+-------+-----+\n",
      "|   APPL|    4|\n",
      "|   GOOG|    3|\n",
      "|     FB|    2|\n",
      "|   MSFT|    3|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Company\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a1b9efe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|   GOOG|    Sam|200.0|\n",
      "|   GOOG|Charlie|120.0|\n",
      "|   GOOG|  Frank|340.0|\n",
      "|   MSFT|   Tina|600.0|\n",
      "|   MSFT|    Amy|124.0|\n",
      "|   MSFT|Vanessa|243.0|\n",
      "|     FB|   Carl|870.0|\n",
      "|     FB|  Sarah|350.0|\n",
      "|   APPL|   John|250.0|\n",
      "|   APPL|  Linda|130.0|\n",
      "|   APPL|   Mike|750.0|\n",
      "|   APPL|  Chris|350.0|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3991da78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(Sales)|\n",
      "+----------+\n",
      "|    4327.0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg({\"Sales\": \"sum\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3f311fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|max(Sales)|\n",
      "+----------+\n",
      "|     870.0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg({\"Sales\": \"max\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "70e87fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_data = df.groupBy(\"Company\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "36a56527",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|Company|max(Sales)|\n",
      "+-------+----------+\n",
      "|   APPL|     750.0|\n",
      "|   GOOG|     340.0|\n",
      "|     FB|     870.0|\n",
      "|   MSFT|     600.0|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "group_data.agg({\"Sales\": \"max\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5fa4a573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|Company|max(Sales)|\n",
      "+-------+----------+\n",
      "|   APPL|     750.0|\n",
      "|   GOOG|     340.0|\n",
      "|     FB|     870.0|\n",
      "|   MSFT|     600.0|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby(\"Company\").max().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2b47e583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, countDistinct, stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e4091b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|count(DISTINCT Sales)|\n",
      "+---------------------+\n",
      "|                   11|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(countDistinct(\"Sales\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fedb760c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       avg(Sales)|\n",
      "+-----------------+\n",
      "|360.5833333333333|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(avg(\"Sales\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "14e7e5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|    Average Sales|\n",
      "+-----------------+\n",
      "|360.5833333333333|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(avg(\"Sales\").alias(\"Average Sales\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1891f7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|stddev_samp(Sales)|\n",
      "+------------------+\n",
      "|250.08742410799007|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(stddev(\"Sales\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f41da650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import format_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "47d0a84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|   std|\n",
      "+------+\n",
      "|250.09|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(stddev(\"Sales\").alias(\"std\")).select(format_number('std', 2).alias('std')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "19057ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|   GOOG|    Sam|200.0|\n",
      "|   GOOG|Charlie|120.0|\n",
      "|   GOOG|  Frank|340.0|\n",
      "|   MSFT|   Tina|600.0|\n",
      "|   MSFT|    Amy|124.0|\n",
      "|   MSFT|Vanessa|243.0|\n",
      "|     FB|   Carl|870.0|\n",
      "|     FB|  Sarah|350.0|\n",
      "|   APPL|   John|250.0|\n",
      "|   APPL|  Linda|130.0|\n",
      "|   APPL|   Mike|750.0|\n",
      "|   APPL|  Chris|350.0|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "266da5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|   GOOG|Charlie|120.0|\n",
      "|   MSFT|    Amy|124.0|\n",
      "|   APPL|  Linda|130.0|\n",
      "|   GOOG|    Sam|200.0|\n",
      "|   MSFT|Vanessa|243.0|\n",
      "|   APPL|   John|250.0|\n",
      "|   GOOG|  Frank|340.0|\n",
      "|     FB|  Sarah|350.0|\n",
      "|   APPL|  Chris|350.0|\n",
      "|   MSFT|   Tina|600.0|\n",
      "|   APPL|   Mike|750.0|\n",
      "|     FB|   Carl|870.0|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(\"Sales\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3db396a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|     FB|   Carl|870.0|\n",
      "|   APPL|   Mike|750.0|\n",
      "|   MSFT|   Tina|600.0|\n",
      "|     FB|  Sarah|350.0|\n",
      "|   APPL|  Chris|350.0|\n",
      "|   GOOG|  Frank|340.0|\n",
      "|   APPL|   John|250.0|\n",
      "|   MSFT|Vanessa|243.0|\n",
      "|   GOOG|    Sam|200.0|\n",
      "|   APPL|  Linda|130.0|\n",
      "|   MSFT|    Amy|124.0|\n",
      "|   GOOG|Charlie|120.0|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(df[\"Sales\"].desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eede97ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca26ea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init(\"/home/danial/spark-3.3.2-bin-hadoop3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "991057d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e10efed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/31 15:16:31 WARN Utils: Your hostname, danial-VirtualBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "23/03/31 15:16:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/31 15:16:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/03/31 15:16:33 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/03/31 15:16:33 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"miss\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65c5e62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(directory + \"ContainsNull.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc923d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| null|\n",
      "|emp2| null| null|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6212dc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b132add0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| null|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "137da528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(how='any').show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51fe2f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| null|\n",
      "|emp2| null| null|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(how='all').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b325970d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(subset=['Sales']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5efe2e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9030b740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-----+\n",
      "|  Id|      Name|Sales|\n",
      "+----+----------+-----+\n",
      "|emp1|      John| null|\n",
      "|emp2|FILL VALUE| null|\n",
      "|emp3|FILL VALUE|345.0|\n",
      "|emp4|     Cindy|456.0|\n",
      "+----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill('FILL VALUE').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a0d0f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John|  0.0|\n",
      "|emp2| null|  0.0|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8337bf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-----+\n",
      "|  Id|   Name|Sales|\n",
      "+----+-------+-----+\n",
      "|emp1|   John| null|\n",
      "|emp2|No Name| null|\n",
      "|emp3|No Name|345.0|\n",
      "|emp4|  Cindy|456.0|\n",
      "+----+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill('No Name', subset=['Name']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3a5bf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e6895515",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_val = df.select(mean(df['Sales'])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0df8cce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sales = mean_val[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d430e391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John|400.5|\n",
      "|emp2| null|400.5|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(mean_sales, ['Sales']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5e482953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John|400.5|\n",
      "|emp2| null|400.5|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(df.select(mean(df['Sales'])).collect()[0][0], ['Sales']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2cc76f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5575cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init(\"/home/danial/spark-3.3.2-bin-hadoop3\")\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cc810f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fcf1070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/03 08:45:03 WARN Utils: Your hostname, danial-VirtualBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "23/04/03 08:45:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/03 08:45:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('dates').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34799d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(directory + 'appl_stock.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "551a81f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Date=datetime.datetime(2010, 1, 4, 0, 0), Open=213.429998, High=214.499996, Low=212.38000099999996, Close=214.009998, Volume=123432400, Adj Close=27.727039)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eb40ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|               Date|              Open|              High|               Low|             Close|   Volume|         Adj Close|\n",
      "+-------------------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|2010-01-04 00:00:00|        213.429998|        214.499996|212.38000099999996|        214.009998|123432400|         27.727039|\n",
      "|2010-01-05 00:00:00|        214.599998|        215.589994|        213.249994|        214.379993|150476200|27.774976000000002|\n",
      "|2010-01-06 00:00:00|        214.379993|            215.23|        210.750004|        210.969995|138040000|27.333178000000004|\n",
      "|2010-01-07 00:00:00|            211.75|        212.000006|        209.050005|            210.58|119282800|          27.28265|\n",
      "|2010-01-08 00:00:00|        210.299994|        212.000006|209.06000500000002|211.98000499999998|111902700|         27.464034|\n",
      "|2010-01-11 00:00:00|212.79999700000002|        213.000002|        208.450005|210.11000299999998|115557400|         27.221758|\n",
      "|2010-01-12 00:00:00|209.18999499999998|209.76999500000002|        206.419998|        207.720001|148614900|          26.91211|\n",
      "|2010-01-13 00:00:00|        207.870005|210.92999500000002|        204.099998|        210.650002|151473000|          27.29172|\n",
      "|2010-01-14 00:00:00|210.11000299999998|210.45999700000002|        209.020004|            209.43|108223500|         27.133657|\n",
      "|2010-01-15 00:00:00|210.92999500000002|211.59999700000003|        205.869999|            205.93|148516900|26.680197999999997|\n",
      "|2010-01-19 00:00:00|        208.330002|215.18999900000003|        207.240004|        215.039995|182501900|27.860484999999997|\n",
      "|2010-01-20 00:00:00|        214.910006|        215.549994|        209.500002|            211.73|153038200|         27.431644|\n",
      "|2010-01-21 00:00:00|        212.079994|213.30999599999998|        207.210003|        208.069996|152038600|         26.957455|\n",
      "|2010-01-22 00:00:00|206.78000600000001|        207.499996|            197.16|            197.75|220441900|         25.620401|\n",
      "|2010-01-25 00:00:00|202.51000200000001|        204.699999|        200.190002|        203.070002|266424900|26.309658000000002|\n",
      "|2010-01-26 00:00:00|205.95000100000001|        213.710005|        202.580004|        205.940001|466777500|         26.681494|\n",
      "|2010-01-27 00:00:00|        206.849995|            210.58|        199.530001|        207.880005|430642100|26.932840000000002|\n",
      "|2010-01-28 00:00:00|        204.930004|        205.500004|        198.699995|        199.289995|293375600|25.819922000000002|\n",
      "|2010-01-29 00:00:00|        201.079996|        202.199995|        190.250002|        192.060003|311488100|         24.883208|\n",
      "|2010-02-01 00:00:00|192.36999699999998|             196.0|191.29999899999999|        194.729998|187469100|         25.229131|\n",
      "+-------------------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afa5cda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+\n",
      "|               Date|              Open|\n",
      "+-------------------+------------------+\n",
      "|2010-01-04 00:00:00|        213.429998|\n",
      "|2010-01-05 00:00:00|        214.599998|\n",
      "|2010-01-06 00:00:00|        214.379993|\n",
      "|2010-01-07 00:00:00|            211.75|\n",
      "|2010-01-08 00:00:00|        210.299994|\n",
      "|2010-01-11 00:00:00|212.79999700000002|\n",
      "|2010-01-12 00:00:00|209.18999499999998|\n",
      "|2010-01-13 00:00:00|        207.870005|\n",
      "|2010-01-14 00:00:00|210.11000299999998|\n",
      "|2010-01-15 00:00:00|210.92999500000002|\n",
      "|2010-01-19 00:00:00|        208.330002|\n",
      "|2010-01-20 00:00:00|        214.910006|\n",
      "|2010-01-21 00:00:00|        212.079994|\n",
      "|2010-01-22 00:00:00|206.78000600000001|\n",
      "|2010-01-25 00:00:00|202.51000200000001|\n",
      "|2010-01-26 00:00:00|205.95000100000001|\n",
      "|2010-01-27 00:00:00|        206.849995|\n",
      "|2010-01-28 00:00:00|        204.930004|\n",
      "|2010-01-29 00:00:00|        201.079996|\n",
      "|2010-02-01 00:00:00|192.36999699999998|\n",
      "+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([\"Date\", \"Open\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3510b663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import (year, weekofyear, dayofmonth,\n",
    "                                   dayofyear, hour,dayofweek, month,\n",
    "                                   format_number, date_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52d4b19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|hour(Date)|\n",
      "+----------+\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(hour(df[\"Date\"])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9072ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|dayofmonth(Date)|\n",
      "+----------------+\n",
      "|               4|\n",
      "|               5|\n",
      "|               6|\n",
      "|               7|\n",
      "|               8|\n",
      "|              11|\n",
      "|              12|\n",
      "|              13|\n",
      "|              14|\n",
      "|              15|\n",
      "|              19|\n",
      "|              20|\n",
      "|              21|\n",
      "|              22|\n",
      "|              25|\n",
      "|              26|\n",
      "|              27|\n",
      "|              28|\n",
      "|              29|\n",
      "|               1|\n",
      "+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(dayofmonth(df[\"Date\"])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7166d007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|hour(Date)|\n",
      "+----------+\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(hour(df[\"Date\"])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecdf111d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|month(Date)|\n",
      "+-----------+\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          2|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(month(df['Date'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "723b9969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ddcef442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|year(Date)|\n",
      "+----------+\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8eb2cae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|year(Date)|\n",
      "+----------+\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "|      2010|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(year(df['Date'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6a2c91c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = df.withColumn('Year', year(df['Date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d7e6e238",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|Year|        avg(Close)|\n",
      "+----+------------------+\n",
      "|2015|120.03999980555547|\n",
      "|2013| 472.6348802857143|\n",
      "|2014| 295.4023416507935|\n",
      "|2012| 576.0497195640002|\n",
      "|2016|104.60400786904763|\n",
      "|2010| 259.8424600000002|\n",
      "|2011|364.00432532142867|\n",
      "+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# avg closing price per year\n",
    "\n",
    "newdf.groupBy('Year').mean().select(['Year', 'avg(Close)']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9aa60d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = newdf.groupBy('Year').mean().select(['Year', 'avg(Close)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8ef32588",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_result = result#.withColumnRenamed(\"avg(Close)\", \"Average Closing Price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6469bf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|Year|        avg(Close)|\n",
      "+----+------------------+\n",
      "|2015|120.03999980555547|\n",
      "|2013| 472.6348802857143|\n",
      "|2014| 295.4023416507935|\n",
      "|2012| 576.0497195640002|\n",
      "|2016|104.60400786904763|\n",
      "|2010| 259.8424600000002|\n",
      "|2011|364.00432532142867|\n",
      "+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "00baa92a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------+\n",
      "|Year|Average Closing Price|\n",
      "+----+---------------------+\n",
      "|2015|               120.04|\n",
      "|2013|               472.63|\n",
      "|2014|               295.40|\n",
      "|2012|               576.05|\n",
      "|2016|               104.60|\n",
      "|2010|               259.84|\n",
      "|2011|               364.00|\n",
      "+----+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_result.select([\"Year\", format_number(\"avg(Close)\", 2).alias(\"Average Closing Price\")]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6b2900",
   "metadata": {},
   "source": [
    "# Spark DataFrames Project Exercise "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4376fb89",
   "metadata": {},
   "source": [
    "#### Use the walmart_stock.csv file to Answer and complete the  tasks below!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ca1bc2",
   "metadata": {},
   "source": [
    "#### Start a simple Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "978a2282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dec0aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init(\"/home/danial/spark-3.3.2-bin-hadoop3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "225bc346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d979fb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/03 12:13:26 WARN Utils: Your hostname, danial-VirtualBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "23/04/03 12:13:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/03 12:13:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"walmart stock\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b9f6ed",
   "metadata": {},
   "source": [
    "#### Load the Walmart Stock CSV File, have Spark infer the data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d8b3dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"/home/danial/Desktop/myspark/Apache-Spark/Python-and-Spark-for-Big-Data-master/Spark_DataFrame_Project_Exercise/walmart_stock.csv\",\n",
    "                   header=True,\n",
    "                   inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c916982b",
   "metadata": {},
   "source": [
    "#### What are the column names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da56b2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e2cb52",
   "metadata": {},
   "source": [
    "#### What does the Schema look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0db3b66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0015739",
   "metadata": {},
   "source": [
    "#### Print out the first 5 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3437074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+------------------+------------------+\n",
      "|               Date|              Open|              High|               Low|             Close|\n",
      "+-------------------+------------------+------------------+------------------+------------------+\n",
      "|2012-01-03 00:00:00|         59.970001|         61.060001|         59.869999|         60.330002|\n",
      "|2012-01-04 00:00:00|60.209998999999996|         60.349998|         59.470001|59.709998999999996|\n",
      "|2012-01-05 00:00:00|         59.349998|         59.619999|         58.369999|         59.419998|\n",
      "|2012-01-06 00:00:00|         59.419998|         59.450001|         58.869999|              59.0|\n",
      "|2012-01-09 00:00:00|         59.029999|         59.549999|         58.919998|             59.18|\n",
      "|2012-01-10 00:00:00|             59.43|59.709998999999996|             58.98|59.040001000000004|\n",
      "|2012-01-11 00:00:00|         59.060001|         59.529999|59.040001000000004|         59.400002|\n",
      "|2012-01-12 00:00:00|59.790001000000004|              60.0|         59.400002|              59.5|\n",
      "|2012-01-13 00:00:00|             59.18|59.610001000000004|59.009997999999996|59.540001000000004|\n",
      "|2012-01-17 00:00:00|         59.869999|60.110001000000004|             59.52|         59.849998|\n",
      "|2012-01-18 00:00:00|59.790001000000004|         60.029999|         59.650002|60.009997999999996|\n",
      "|2012-01-19 00:00:00|             59.93|             60.73|             59.75|60.610001000000004|\n",
      "|2012-01-20 00:00:00|             60.75|             61.25|         60.669998|61.009997999999996|\n",
      "|2012-01-23 00:00:00|         60.810001|             60.98|60.509997999999996|             60.91|\n",
      "|2012-01-24 00:00:00|             60.75|              62.0|             60.75|61.389998999999996|\n",
      "|2012-01-25 00:00:00|             61.18|61.610001000000004|61.040001000000004|         61.470001|\n",
      "|2012-01-26 00:00:00|         61.799999|             61.84|             60.77|         60.970001|\n",
      "|2012-01-27 00:00:00|60.860001000000004|         61.119999|60.540001000000004|60.709998999999996|\n",
      "|2012-01-30 00:00:00|         60.470001|             61.32|         60.349998|         61.299999|\n",
      "|2012-01-31 00:00:00|         61.529999|             61.57|         60.580002|61.360001000000004|\n",
      "+-------------------+------------------+------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.columns[:5]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329b4671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first five rows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f1b17e42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Date=datetime.datetime(2012, 1, 3, 0, 0), Open=59.970001, High=61.060001, Low=59.869999, Close=60.330002, Volume=12668800, Adj Close=52.619234999999996),\n",
       " Row(Date=datetime.datetime(2012, 1, 4, 0, 0), Open=60.209998999999996, High=60.349998, Low=59.470001, Close=59.709998999999996, Volume=9593300, Adj Close=52.078475),\n",
       " Row(Date=datetime.datetime(2012, 1, 5, 0, 0), Open=59.349998, High=59.619999, Low=58.369999, Close=59.419998, Volume=12768200, Adj Close=51.825539),\n",
       " Row(Date=datetime.datetime(2012, 1, 6, 0, 0), Open=59.419998, High=59.450001, Low=58.869999, Close=59.0, Volume=8069400, Adj Close=51.45922),\n",
       " Row(Date=datetime.datetime(2012, 1, 9, 0, 0), Open=59.029999, High=59.549999, Low=58.919998, Close=59.18, Volume=6679300, Adj Close=51.616215000000004)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "982cc4c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Date=datetime.datetime(2012, 1, 3, 0, 0), Open=59.970001, High=61.060001, Low=59.869999, Close=60.330002, Volume=12668800, Adj Close=52.619234999999996) \n",
      "\n",
      "Row(Date=datetime.datetime(2012, 1, 4, 0, 0), Open=60.209998999999996, High=60.349998, Low=59.470001, Close=59.709998999999996, Volume=9593300, Adj Close=52.078475) \n",
      "\n",
      "Row(Date=datetime.datetime(2012, 1, 5, 0, 0), Open=59.349998, High=59.619999, Low=58.369999, Close=59.419998, Volume=12768200, Adj Close=51.825539) \n",
      "\n",
      "Row(Date=datetime.datetime(2012, 1, 6, 0, 0), Open=59.419998, High=59.450001, Low=58.869999, Close=59.0, Volume=8069400, Adj Close=51.45922) \n",
      "\n",
      "Row(Date=datetime.datetime(2012, 1, 9, 0, 0), Open=59.029999, High=59.549999, Low=58.919998, Close=59.18, Volume=6679300, Adj Close=51.616215000000004) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for one_row in df.head(5):\n",
    "    print (one_row, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831166ee",
   "metadata": {},
   "source": [
    "#### Use describe() to learn about the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1cf5c438",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|summary|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|  count|              1258|             1258|             1258|             1258|             1258|             1258|\n",
      "|   mean| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
      "| stddev|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n",
      "|    min|56.389998999999996|        57.060001|        56.299999|        56.419998|          2094900|        50.363689|\n",
      "|    max|         90.800003|        90.970001|            89.25|        90.470001|         80898100|84.91421600000001|\n",
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6f86b1",
   "metadata": {},
   "source": [
    "## Bonus Question!\n",
    "#### There are too many decimal places for mean and stddev in the describe() dataframe. Format the numbers to just show up to two decimal places. Pay careful attention to the datatypes that .describe() returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7a6e004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- summary: string (nullable = true)\n",
      " |-- Open: string (nullable = true)\n",
      " |-- High: string (nullable = true)\n",
      " |-- Low: string (nullable = true)\n",
      " |-- Close: string (nullable = true)\n",
      " |-- Volume: string (nullable = true)\n",
      " |-- Adj Close: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a53c84b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5e4548a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['summary', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55e7154b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('summary', 'string'),\n",
       " ('Open', 'string'),\n",
       " ('High', 'string'),\n",
       " ('Low', 'string'),\n",
       " ('Close', 'string'),\n",
       " ('Volume', 'string'),\n",
       " ('Adj Close', 'string')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce96a0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------+--------+--------+\n",
      "|summary|    Open|    High|     Low|   Close|  Volume|\n",
      "+-------+--------+--------+--------+--------+--------+\n",
      "|  count|1,258.00|1,258.00|1,258.00|1,258.00|    1258|\n",
      "|   mean|   72.36|   72.84|   71.92|   72.39| 8222093|\n",
      "| stddev|    6.77|    6.77|    6.74|    6.76| 4519780|\n",
      "|    min|   56.39|   57.06|   56.30|   56.42| 2094900|\n",
      "|    max|   90.80|   90.97|   89.25|   90.47|80898100|\n",
      "+-------+--------+--------+--------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import format_number\n",
    "\n",
    "result.select(result['summary'],\n",
    "             format_number(result['Open'].cast('float'),2).alias('Open'),\n",
    "             format_number(result['High'].cast('float'), 2).alias('High'),\n",
    "             format_number(result['Low'].cast('float'),2).alias('Low'),\n",
    "             format_number(result['Close'].cast('float'),2).alias('Close'),\n",
    "             result['Volume'].cast('int').alias('Volume')\n",
    "             ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b3c269",
   "metadata": {},
   "source": [
    "#### Create a new dataframe with a column called HV Ratio that is the ratio of the High Price versus volume of stock traded for a day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3d2e0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6c41670",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = df.withColumn('HV Ratio', df['High']/df['Volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44c8a3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            HV Ratio|\n",
      "+--------------------+\n",
      "|4.819714653321546E-6|\n",
      "|6.290848613094555E-6|\n",
      "|4.669412994783916E-6|\n",
      "|7.367338463826307E-6|\n",
      "|8.915604778943901E-6|\n",
      "|8.644477436914568E-6|\n",
      "|9.351828421515645E-6|\n",
      "| 8.29141562102703E-6|\n",
      "|7.712212102001476E-6|\n",
      "|7.071764823529412E-6|\n",
      "|1.015495466386981E-5|\n",
      "|6.576354146362592...|\n",
      "| 5.90145296180676E-6|\n",
      "|8.547679455011844E-6|\n",
      "|8.420709512685392E-6|\n",
      "|1.041448341728929...|\n",
      "|8.316075414862431E-6|\n",
      "|9.721183814992126E-6|\n",
      "|8.029436027707578E-6|\n",
      "|6.307432259386365E-6|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf.select('HV Ratio').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a071eaa6",
   "metadata": {},
   "source": [
    "#### What day had the Peak High in Price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "ca163b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.970001"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_high = newdf.agg({'High': 'max'}).collect()\n",
    "max_high[0][0]\n",
    "# df.select(hour(df[\"Date\"])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "e7840c4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|               Date|\n",
      "+-------------------+\n",
      "|2015-01-13 00:00:00|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf.filter(newdf['High'] == max_high[0][0]).select(['Date']).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c333704f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2015, 1, 13, 0, 0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# easier solution\n",
    "df.orderBy(df['High'].desc()).head(1)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3018d916",
   "metadata": {},
   "source": [
    "#### What is the mean of the Close column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6a09a572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       avg(Close)|\n",
      "+-----------------+\n",
      "|72.38844998012726|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, mean # both should be working the same way \n",
    "df.select(avg('Close')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1974fbff",
   "metadata": {},
   "source": [
    "#### What is the max and min of the Volume column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cf55fe6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|max(Volume)|min(Volume)|\n",
      "+-----------+-----------+\n",
      "|   80898100|    2094900|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import min, max\n",
    "\n",
    "df.agg(max('Volume'), min('Volume')).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "581c0e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|max(Volume)|min(Volume)|\n",
      "+-----------+-----------+\n",
      "|   80898100|    2094900|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# another way to achieve the same results\n",
    "\n",
    "df.select(max('Volume'), min('Volume')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ce278b",
   "metadata": {},
   "source": [
    "#### How many days was the Close lower than 60 dollars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "e42c6a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# python way\n",
    "df.filter(df['Close'] < 60).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f3523d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sql way\n",
    "df.filter('Close < 60').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439884a7",
   "metadata": {},
   "source": [
    "#### What percentage of the time was the High greater than 80 dollars ?\n",
    "#### In other words, (Number of Days High>80)/(Total Days in the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d864a48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.141494435612083"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df['High'] > 80).count()/df.count()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6931f1e2",
   "metadata": {},
   "source": [
    "#### What is the Pearson correlation between High and Volume?\n",
    "#### [Hint](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrameStatFunctions.corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "970e2d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "| corr(Volume, High)|\n",
      "+-------------------+\n",
      "|-0.3384326061737161|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import corr\n",
    "df.select(corr('Volume', 'High')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f149d9c",
   "metadata": {},
   "source": [
    "#### What is the max High per year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "f59d6b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "c38cde51",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf = df.withColumn('Year', year(df['Date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "f68c0204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|Year|max(High)|\n",
      "+----+---------+\n",
      "|2015|90.970001|\n",
      "|2013|81.370003|\n",
      "|2014|88.089996|\n",
      "|2012|77.599998|\n",
      "|2016|75.190002|\n",
      "+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mydf.groupBy('Year').max().select(['Year', 'max(High)']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61e3a7c",
   "metadata": {},
   "source": [
    "#### What is the average Close for each Calendar Month?\n",
    "#### In other words, across all the years, what is the average Close price for Jan,Feb, Mar, etc... Your result will have a value for each of these months. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "5c64702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mynewdf = df.withColumn('Month', month(df['Date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "372d9bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|month|       avg(Close)|\n",
      "+-----+-----------------+\n",
      "|    1|71.44801958415842|\n",
      "|    2|  71.306804443299|\n",
      "|    3|71.77794377570092|\n",
      "|    4|72.97361900952382|\n",
      "|    5|72.30971688679247|\n",
      "|    6| 72.4953774245283|\n",
      "|    7|74.43971943925233|\n",
      "|    8|73.02981855454546|\n",
      "|    9|72.18411785294116|\n",
      "|   10|71.57854545454543|\n",
      "|   11| 72.1110893069307|\n",
      "|   12|72.84792478301885|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mynewdf.groupBy('month').mean().select('month', 'avg(Close)').orderBy('month').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1ee738",
   "metadata": {},
   "source": [
    "# Intro to Machine Learning with MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d183223",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
